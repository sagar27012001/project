{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f_oECWHJ3h8"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import ZeroPadding2D,Conv2D,BatchNormalization,Dense,Flatten,Concatenate,Activation,Input,LeakyReLU,MaxPooling2D,GlobalAveragePooling2D,AveragePooling2D,Dropout\n",
        "from tensorflow.keras.models import Model,load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import cv2 as cv\n",
        "from PIL import Image,ImageDraw\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import argparse\n",
        "import xml.etree.ElementTree as ET\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIUtsOkoKTzX"
      },
      "source": [
        "classes_num = {'aeroplane': 0, 'bicycle': 1, 'bird': 2, 'boat': 3, 'bottle': 4, 'bus': 5,\n",
        "               'car': 6, 'cat': 7, 'chair': 8, 'cow': 9, 'diningtable': 10, 'dog': 11,\n",
        "               'horse': 12, 'motorbike': 13, 'person': 14, 'pottedplant': 15, 'sheep': 16,\n",
        "               'sofa': 17, 'train': 18, 'tvmonitor': 19}\n",
        "sets = [\"train\",\"val\"]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fsif5_umhca",
        "outputId": "9959ab3e-c957-4e74-a7fe-de70724845e5"
      },
      "source": [
        "root = ET.parse(\"/content/drive/MyDrive/YOLO/VOC2007/VOCdevkit/VOC2007/Annotations/000005.xml\")\n",
        "root.getroot()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Element 'annotation' at 0x7fc893c7fd10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9f93OPVmppk"
      },
      "source": [
        "def convert_annotation(image_id,f):\n",
        "  file_path = os.path.join(\"/content/drive/MyDrive/YOLO/VOC2007/VOCdevkit/VOC2007/Annotations/%s.xml\" %(image_id))\n",
        "  tree = ET.parse(file_path)\n",
        "  root = tree.getroot()\n",
        "\n",
        "  for obj in root.iter(\"object\"):\n",
        "    cls_name = obj.find(\"name\").text\n",
        "    difficult = obj.find(\"difficult\").text\n",
        "    classes = list(classes_num.keys())\n",
        "\n",
        "    if cls_name not in classes or int(difficult) == 1:\n",
        "      continue\n",
        "    \n",
        "    cls_id = classes_num[cls_name]\n",
        "    b_box = obj.find(\"bndbox\")\n",
        "\n",
        "    box = (int(b_box.find('xmin').text), int(b_box.find('ymin').text),\n",
        "             int(b_box.find('xmax').text), int(b_box.find('ymax').text))\n",
        "\n",
        "    f.write(\" \" + \",\".join([str(a) for a in box]) + \",\" + str(cls_id))\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysuXXVMQm1Fq",
        "outputId": "dbd450a8-bda2-405d-d5f7-4f8f8527d3b8"
      },
      "source": [
        "for image_set in sets:\n",
        "  print(image_set)\n",
        "  with open(os.path.join(\"/content/drive/MyDrive/YOLO/VOC2007/VOCdevkit/VOC2007/ImageSets/Main/%s.txt\"%(image_set)),\"r\") as f:\n",
        "    image_ids = f.read().strip().split()\n",
        "    \n",
        "  with open(os.path.join(\"/content/drive/MyDrive/YOLO/VOC2007/VOCdevkit\", 'My_%s.txt' % (image_set)), 'w') as f:\n",
        "      for image_id in image_ids:\n",
        "          f.write('/content/drive/MyDrive/YOLO/VOC2007/VOCdevkit/VOC%s/JPEGImages/%s.jpg' % (str(2007), image_id))\n",
        "          convert_annotation(image_id, f)\n",
        "          f.write('\\n')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg2ktEK6r-pR"
      },
      "source": [
        "def read(image_path,label):\n",
        "  image = Image.open(image_path)\n",
        "  image_w, image_h = image.size\n",
        "  image = image.resize((448,448))\n",
        "  image = np.array(image) / 255.\n",
        "\n",
        "\n",
        "  label_matrix = np.zeros((7,7,30))\n",
        "  \n",
        "  for l in label:\n",
        "    l = l.split(\",\")\n",
        "    l = np.array(l,dtype=np.int)\n",
        "    xmin = l[0]\n",
        "    ymin = l[1]\n",
        "    xmax = l[2]\n",
        "    ymax = l[3]\n",
        "    cls_id = l[4]\n",
        "\n",
        "    x = (xmin + xmax) / 2 / image_w\n",
        "    y = (ymin + ymax) / 2 / image_h\n",
        "    w = (xmax - xmin) / image_w\n",
        "    h = (ymax - ymin) / image_h\n",
        "\n",
        "    loc = [7*x, 7*y]\n",
        "    loc_i = int(loc[1])\n",
        "    loc_j = int(loc[0])\n",
        "\n",
        "    y = loc[1] - loc_i\n",
        "    x = loc[0] - loc_j\n",
        "\n",
        "    if label_matrix[loc_i,loc_j,24] == 0:\n",
        "      label_matrix[loc_i, loc_j, cls_id] = 1\n",
        "      label_matrix[loc_i,loc_j,20:24] = [x, y, w, h]\n",
        "      label_matrix[loc_i,loc_j,24] = 1\n",
        "\n",
        "    return image, label_matrix"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvTO-FuZ4FcW"
      },
      "source": [
        "class img_generator(keras.utils.Sequence):\n",
        "  def __init__(self,x,y,batch_size):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def __len__(self):\n",
        "    temp = int(np.ceil(len(self.x) / self.batch_size))\n",
        "    return temp\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    batch_x = self.x[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "    batch_y = self.y[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "\n",
        "    train_image = []\n",
        "    train_label = []\n",
        "\n",
        "    for i in range(0, len(batch_x)):\n",
        "      img_path = batch_x[i]\n",
        "      label = batch_y[i]\n",
        "      image, label_matrix = read(img_path, label)\n",
        "      train_image.append(image)\n",
        "      train_label.append(label_matrix)\n",
        "      \n",
        "    return np.array(train_image), np.array(train_label)\n",
        "    "
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZB5C42GFT0a"
      },
      "source": [
        "img_path = []\n",
        "\n",
        "for i in glob.glob(\"/content/drive/MyDrive/YOLO/VOC2007/VOCdevkit/VOC2007/JPEGImages/*\"):\n",
        "  img_path.append(i)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiwRE4Qk7V9f"
      },
      "source": [
        "x_train_dataset = []\n",
        "x_val_dataset = []\n",
        "\n",
        "with open(\"/content/drive/MyDrive/YOLO/VOC2007/VOCdevkit/My_train.txt\",\"r\") as f:\n",
        "  x_train_dataset += f.readlines()\n",
        "\n",
        "with open(\"/content/drive/MyDrive/YOLO/VOC2007/VOCdevkit/My_val.txt\",\"r\") as f:\n",
        "  x_val_dataset += f.readlines()\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "x_val = []\n",
        "y_val = []\n",
        "\n",
        "for item in x_train_dataset:\n",
        "  item = item.replace(\"\\n\",\"\").split(\" \")\n",
        "  if item[0] in img_path:\n",
        "    x_train.append(item[0])\n",
        "    temp = []\n",
        "    for i in range(1, len(item)):\n",
        "      temp.append(item[i])\n",
        "\n",
        "    y_train.append(temp)\n",
        "\n",
        "\n",
        "for item in x_val_dataset:\n",
        "  item = item.replace(\"\\n\",\"\").split(\" \")\n",
        "  if item[0] in img_path:\n",
        "    x_val.append(item[0])\n",
        "    temp = []\n",
        "    for i in range(1, len(item)):\n",
        "      temp.append(item[i])\n",
        "\n",
        "    y_val.append(temp)\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEM7OEQC-UX3"
      },
      "source": [
        "batch_size = 64 #64 used in YOLO paper\n",
        "\n",
        "train_gen = img_generator(x_train, y_train, batch_size)\n",
        "val_gen = img_generator(x_val, y_val, batch_size)\n",
        "\n",
        "train_x, train_y = train_gen.__getitem__(1)\n",
        "val_x, val_y = val_gen.__getitem__(1)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ajjhs1_UAB85",
        "outputId": "1f71685e-03ec-4e64-8318-a5e1b7b14ee2"
      },
      "source": [
        "train_x.shape,train_y.shape,val_x.shape,val_y.shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((64, 448, 448, 3), (64, 7, 7, 30), (64, 448, 448, 3), (64, 7, 7, 30))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQyuSgPsAgFP"
      },
      "source": [
        "class reshape_op(tf.keras.layers.Layer):\n",
        "  \n",
        "  def __init__(self,target_shape):\n",
        "    super(reshape_op,self).__init__()\n",
        "    self.target_shape = tuple(target_shape)\n",
        "\n",
        "  def getconfig(self):\n",
        "    config = super().getconfig.copy()\n",
        "    config.update({\"target_shape\":self.target_shape})\n",
        "    return config\n",
        "\n",
        "  def call(self,input):\n",
        "    s = [self.target_shape[0],self.target_shape[1]] #Grid size\n",
        "    c = 20 #classes\n",
        "    b = 2 #boxes\n",
        "    idx1 = s[0] * s[1] * c\n",
        "    idx2 =  idx1 + s[0] * s[1] * b\n",
        "  \n",
        "    class_probs = K.reshape(input[:, :idx1], (K.shape(input)[0],) + tuple([s[0], s[1], c]))\n",
        "    class_probs = K.softmax(class_probs)\n",
        "\n",
        "    #confidence\n",
        "    confs = K.reshape(input[:, idx1:idx2], (K.shape(input)[0],) + tuple([s[0], s[1], b]))\n",
        "    confs = K.sigmoid(confs)\n",
        "\n",
        "    # boxes\n",
        "    boxes = K.reshape(input[:, idx2:], (K.shape(input)[0],) + tuple([s[0], s[1], b * 4]))\n",
        "    boxes = K.sigmoid(boxes)\n",
        "\n",
        "    outputs = K.concatenate([class_probs, confs, boxes])\n",
        "    return outputs"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6XPsBBgfy3k"
      },
      "source": [
        "def my_model(input_shape = (448,448,3)):\n",
        "  base_model = tf.keras.applications.InceptionResNetV2(\n",
        "      input_shape = (448,448,3),\n",
        "      weights = \"imagenet\",\n",
        "      include_top = False\n",
        "  )\n",
        "  base_model.trainable = False\n",
        "  inputs = Input(shape = input_shape)\n",
        "  x = base_model(inputs)\n",
        "  x = MaxPooling2D(pool_size = 2, strides = 2)(x)\n",
        "  x = Conv2D(filters = 1536, kernel_size = 3, activation = \"relu\")(x)\n",
        "  x = MaxPooling2D(pool_size = 2, strides = 2)(x)\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(units = 2048, activation = \"relu\")(x)\n",
        "  x = Dropout(0.4)(x)\n",
        "  x = Dense(units = 2048, activation = \"relu\")(x)\n",
        "  x = Dropout(0.4)(x)\n",
        "  x = Dense(units = 1470, activation = \"sigmoid\")(x)\n",
        "  x = reshape_op(target_shape=(7,7,30))(x)\n",
        "\n",
        "  model = Model(inputs, x)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVFRETfMhRX1"
      },
      "source": [
        "model = my_model()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xTbRL1SnRdI",
        "outputId": "763b53b5-6904-421d-fc88-dbe4dc48cb4e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        [(None, 448, 448, 3)]     0         \n",
            "_________________________________________________________________\n",
            "inception_resnet_v2 (Functio (None, 12, 12, 1536)      54336736  \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 6, 6, 1536)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1422 (Conv2D)         (None, 4, 4, 1536)        21235200  \n",
            "_________________________________________________________________\n",
            "max_pooling2d_34 (MaxPooling (None, 2, 2, 1536)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 1536)              0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1536)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 2048)              3147776   \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1470)              3012030   \n",
            "_________________________________________________________________\n",
            "reshape_op_4 (reshape_op)    (None, 7, 7, 30)          0         \n",
            "=================================================================\n",
            "Total params: 85,928,094\n",
            "Trainable params: 31,591,358\n",
            "Non-trainable params: 54,336,736\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV-dvERuf102"
      },
      "source": [
        "# def create_model(input_shape=(448,448,3)):\n",
        "#   x_input = Input(input_shape)\n",
        "  \n",
        "#   x = Conv2D(filters=64,kernel_size=(7,7),strides=1,padding=\"same\")(x_input)\n",
        "#   x = BatchNormalization(axis=-1)(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = MaxPooling2D(pool_size=2,strides=2)(x)\n",
        "\n",
        "#   x = Conv2D(filters=192, kernel_size=(3,3), strides=1,padding=\"same\")(x)\n",
        "#   x = BatchNormalization(axis=-1)(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = MaxPooling2D(pool_size=2,strides=2)(x)\n",
        "\n",
        "#   x = Conv2D(filters=128, kernel_size=1)(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = Conv2D(filters=256,kernel_size=3,padding=\"same\")(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = Conv2D(filters=256, kernel_size=1)(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = Conv2D(filters=512,kernel_size=3,padding=\"same\")(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = MaxPooling2D(pool_size=2,strides=2)(x)\n",
        "\n",
        "#   x = Conv2D(filters=256, kernel_size=1)(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = Conv2D(filters=512,kernel_size=3,padding=\"same\")(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = Conv2D(filters=256, kernel_size=1)(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = Conv2D(filters=512,kernel_size=3,padding=\"same\")(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = Conv2D(filters=256, kernel_size=1)(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = Conv2D(filters=512,kernel_size=3,padding=\"same\")(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = Conv2D(filters=256, kernel_size=1)(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = Conv2D(filters=512,kernel_size=3,padding=\"same\")(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = Conv2D(filters=512,kernel_size=1)(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = Conv2D(filters=1024, kernel_size=3, padding=\"same\")(x)\n",
        "#   x = MaxPooling2D(pool_size=2,strides=2)(x)\n",
        "\n",
        "#   x = Conv2D(filters=512, kernel_size=1)(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = Conv2D(filters=1024, kernel_size=3,padding=\"same\")(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = Conv2D(filters=512, kernel_size=1)(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = Conv2D(filters=1024, kernel_size=3,padding=\"same\")(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = Conv2D(filters=1024,kernel_size=3,padding=\"same\")(x)\n",
        "#   x = Conv2D(filters=1024,kernel_size=3,strides=2,padding=\"same\")(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = Conv2D(filters=1024,kernel_size=3,padding=\"valid\")(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "#   x = Conv2D(filters=1024,kernel_size=3,padding=\"valid\")(x)\n",
        "#   x = BatchNormalization()(x)\n",
        "#   x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "#   x = Flatten()(x)\n",
        "#   x = Dense(units=512)(x)\n",
        "#   x = Dense(units=1024)(x)\n",
        "#   x = Dropout(rate=0.5)(x)\n",
        "#   x = Dense(units=1470,activation=\"sigmoid\")(x)\n",
        "#   x = reshape_op(target_shape=(7,7,30))(x)\n",
        "\n",
        "#   mod = Model(inputs=x_input, outputs=x)\n",
        "\n",
        "#   return mod\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvQEiVlIlDra"
      },
      "source": [
        "# mod = model((448,448,3))"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S9kfPeOlNFv"
      },
      "source": [
        "# mod.summary()"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR0li8L9l60T"
      },
      "source": [
        "class CustomLearningRateScheduler(keras.callbacks.Callback):\n",
        "    \"\"\"Learning rate scheduler which sets the learning rate according to schedule.\n",
        "\n",
        "  Arguments:\n",
        "      schedule: a function that takes an epoch index\n",
        "          (integer, indexed from 0) and current learning rate\n",
        "          as inputs and returns a new learning rate as output (float).\n",
        "  \"\"\"\n",
        "\n",
        "    def __init__(self, schedule):\n",
        "        super(CustomLearningRateScheduler, self).__init__()\n",
        "        self.schedule = schedule\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        if not hasattr(self.model.optimizer, \"lr\"):\n",
        "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
        "        # Get the current learning rate from model's optimizer.\n",
        "        lr = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
        "        # Call schedule function to get the scheduled learning rate.\n",
        "        scheduled_lr = self.schedule(epoch, lr)\n",
        "        # Set the value back to the optimizer before this epoch starts\n",
        "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
        "        if epoch == 0 or epoch == 75 or epoch == 105:\n",
        "          print(\"\\nEpoch %d: Learning rate is %f.\" % (epoch, scheduled_lr))\n",
        "\n",
        "\n",
        "LR_SCHEDULE = [\n",
        "    # (epoch to start, learning rate) tuples\n",
        "    (0, 0.01),\n",
        "    (75, 0.001),\n",
        "    (105, 0.0001),\n",
        "]\n",
        "\n",
        "\n",
        "def lr_schedule(epoch, lr):\n",
        "    \"\"\"Helper function to retrieve the scheduled learning rate based on epoch.\"\"\"\n",
        "    if epoch < LR_SCHEDULE[0][0] or epoch > LR_SCHEDULE[-1][0]:\n",
        "        return lr\n",
        "    for i in range(len(LR_SCHEDULE)):\n",
        "        if epoch == LR_SCHEDULE[i][0]:\n",
        "            return LR_SCHEDULE[i][1]\n",
        "    return lr"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc0XLIq6nNCu"
      },
      "source": [
        "def xywh2minmax(xy, wh):\n",
        "    xy_min = xy - wh / 2\n",
        "    xy_max = xy + wh / 2\n",
        "\n",
        "    return xy_min, xy_max"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj3-pGHfn5Q-"
      },
      "source": [
        "def iou(pred_mins, pred_maxes, true_mins, true_maxes):\n",
        "    intersect_mins = K.maximum(pred_mins, true_mins)\n",
        "    intersect_maxes = K.minimum(pred_maxes, true_maxes)\n",
        "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "\n",
        "    pred_wh = pred_maxes - pred_mins\n",
        "    true_wh = true_maxes - true_mins\n",
        "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
        "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
        "\n",
        "    union_areas = pred_areas + true_areas - intersect_areas\n",
        "    iou_scores = intersect_areas / union_areas\n",
        "\n",
        "    return iou_scores"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HxgpMT-oHga"
      },
      "source": [
        "def yolo_head(feats):\n",
        "    conv_dims = K.shape(feats)[1:3]  # assuming channels last\n",
        "    # In YOLO the height index is the inner most iteration.\n",
        "    conv_height_index = K.arange(0, stop=conv_dims[0])\n",
        "    conv_width_index = K.arange(0, stop=conv_dims[1])\n",
        "    conv_height_index = K.tile(conv_height_index, [conv_dims[1]])\n",
        "\n",
        "    # TODO: Repeat_elements and tf.split doesn't support dynamic splits.\n",
        "    # conv_width_index = K.repeat_elements(conv_width_index, conv_dims[1], axis=0)\n",
        "    conv_width_index = K.tile(K.expand_dims(conv_width_index, 0), [conv_dims[0], 1])\n",
        "    conv_width_index = K.flatten(K.transpose(conv_width_index))\n",
        "    conv_index = K.transpose(K.stack([conv_height_index, conv_width_index]))\n",
        "    conv_index = K.reshape(conv_index, [1, conv_dims[0], conv_dims[1], 1, 2])\n",
        "    conv_index = K.cast(conv_index, K.dtype(feats))\n",
        "\n",
        "    conv_dims = K.cast(K.reshape(conv_dims, [1, 1, 1, 1, 2]), K.dtype(feats))\n",
        "\n",
        "    box_xy = (feats[..., :2] + conv_index) / conv_dims * 448\n",
        "    box_wh = feats[..., 2:4] * 448\n",
        "\n",
        "    return box_xy, box_wh\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PyKzvLcoNXM"
      },
      "source": [
        "def yolo_loss(y_true, y_pred):\n",
        "    label_class = y_true[..., :20]  # ? * 7 * 7 * 20\n",
        "    label_box = y_true[..., 20:24]  # ? * 7 * 7 * 4\n",
        "    response_mask = y_true[..., 24]  # ? * 7 * 7\n",
        "    response_mask = K.expand_dims(response_mask)  # ? * 7 * 7 * 1\n",
        "\n",
        "    predict_class = y_pred[..., :20]  # ? * 7 * 7 * 20\n",
        "    predict_trust = y_pred[..., 20:22]  # ? * 7 * 7 * 2\n",
        "    predict_box = y_pred[..., 22:]  # ? * 7 * 7 * 8\n",
        "\n",
        "    _label_box = K.reshape(label_box, [-1, 7, 7, 1, 4])\n",
        "    _predict_box = K.reshape(predict_box, [-1, 7, 7, 2, 4])\n",
        "\n",
        "    label_xy, label_wh = yolo_head(_label_box)  # ? * 7 * 7 * 1 * 2, ? * 7 * 7 * 1 * 2\n",
        "    label_xy = K.expand_dims(label_xy, 3)  # ? * 7 * 7 * 1 * 1 * 2\n",
        "    label_wh = K.expand_dims(label_wh, 3)  # ? * 7 * 7 * 1 * 1 * 2\n",
        "    label_xy_min, label_xy_max = xywh2minmax(label_xy, label_wh)  # ? * 7 * 7 * 1 * 1 * 2, ? * 7 * 7 * 1 * 1 * 2\n",
        "\n",
        "    predict_xy, predict_wh = yolo_head(_predict_box)  # ? * 7 * 7 * 2 * 2, ? * 7 * 7 * 2 * 2\n",
        "    predict_xy = K.expand_dims(predict_xy, 4)  # ? * 7 * 7 * 2 * 1 * 2\n",
        "    predict_wh = K.expand_dims(predict_wh, 4)  # ? * 7 * 7 * 2 * 1 * 2\n",
        "    predict_xy_min, predict_xy_max = xywh2minmax(predict_xy, predict_wh)  # ? * 7 * 7 * 2 * 1 * 2, ? * 7 * 7 * 2 * 1 * 2\n",
        "\n",
        "    iou_scores = iou(predict_xy_min, predict_xy_max, label_xy_min, label_xy_max)  # ? * 7 * 7 * 2 * 1\n",
        "    best_ious = K.max(iou_scores, axis=4)  # ? * 7 * 7 * 2\n",
        "    best_box = K.max(best_ious, axis=3, keepdims=True)  # ? * 7 * 7 * 1\n",
        "\n",
        "    box_mask = K.cast(best_ious >= best_box, K.dtype(best_ious))  # ? * 7 * 7 * 2\n",
        "\n",
        "    no_object_loss = 0.5 * (1 - box_mask * response_mask) * K.square(0 - predict_trust)\n",
        "    object_loss = box_mask * response_mask * K.square(1 - predict_trust)\n",
        "    confidence_loss = no_object_loss + object_loss\n",
        "    confidence_loss = K.sum(confidence_loss)\n",
        "\n",
        "    class_loss = response_mask * K.square(label_class - predict_class)\n",
        "    class_loss = K.sum(class_loss)\n",
        "\n",
        "    _label_box = K.reshape(label_box, [-1, 7, 7, 1, 4])\n",
        "    _predict_box = K.reshape(predict_box, [-1, 7, 7, 2, 4])\n",
        "\n",
        "    label_xy, label_wh = yolo_head(_label_box) \n",
        "    predict_xy, predict_wh = yolo_head(_predict_box)\n",
        "    box_mask = K.expand_dims(box_mask)\n",
        "    response_mask = K.expand_dims(response_mask)\n",
        "\n",
        "    box_loss = 5 * box_mask * response_mask * K.square((label_xy - predict_xy) / 448)\n",
        "    box_loss += 5 * box_mask * response_mask * K.square((K.sqrt(label_wh) - K.sqrt(predict_wh)) / 448)\n",
        "    box_loss = K.sum(box_loss)\n",
        "\n",
        "    loss = confidence_loss + class_loss + box_loss\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1AqiDlEoQxz"
      },
      "source": [
        "model.compile(optimizer=\"adam\",loss=yolo_loss)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IZ8Rk6UoSNW"
      },
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/YOLO/VOC2007/checkpoint/\"\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llfvqbsU05i_"
      },
      "source": [
        "hist = model.fit(train_gen,\n",
        "               epochs=135,\n",
        "               callbacks=[CustomLearningRateScheduler(lr_schedule), model_checkpoint_callback],\n",
        "               validation_data = val_gen\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}